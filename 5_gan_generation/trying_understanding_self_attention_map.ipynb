{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ebf725",
   "metadata": {},
   "source": [
    "# self-Attentionの理解のためのノート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bc97c",
   "metadata": {},
   "source": [
    "#### P268~P269の式やコードでなぜ特徴量が得られるのだろうと不思議に思う。P268のコードを具体的な値で実行した場合、もともとの画素のどの値がどう計算されたかがわからない。このため、シンボルベースで計算することで計算式からの理解を行いたいと思う。\n",
    "#### 以下、具体的なコードとなるが、理解は難しかった。具体的な値の動きと、今回の結果を見比べることにより、理解が深まるのかもしれない"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e45c3",
   "metadata": {},
   "source": [
    "## numpy行列の定義。シンボルで扱えるようにする工夫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718130ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Array:\n",
      "[[[x_0_0_0,      x_0_0_1,     ]\n",
      "  [x_0_1_0,      x_0_1_1,     ]]\n",
      "\n",
      " [[x_1_0_0,      x_1_0_1,     ]\n",
      "  [x_1_1_0,      x_1_1_1,     ]]]\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols\n",
    "import numpy as np\n",
    "\n",
    "#以下、Chat GPTが生成してくれたコードを少し手直し。\n",
    "\n",
    "#結果の見やすさのための設定。\n",
    "np.set_printoptions(linewidth=1000)\n",
    "#np.set_printoptions(formatter={'all': lambda x: f'{x}, '}) #カンマ\n",
    "np.set_printoptions(formatter={'all': lambda x: f'{x},     '}) #@@\n",
    "\n",
    "# 画像のチャネル、幅、高さ\n",
    "#簡単だけど、全貌がわかりにくいかも\n",
    "C = 2\n",
    "W = 2\n",
    "H = 2\n",
    "\n",
    "#複雑だが、様子がわかりやすい\n",
    "#C = 3\n",
    "#W = 3\n",
    "#H = 3\n",
    "\n",
    "\n",
    "# 配列の宣言を行う\n",
    "image_array = np.empty((C, W, H), dtype=object)\n",
    "\n",
    "# 配列に値を設定\n",
    "for c in range(C):\n",
    "    for w in range(W):\n",
    "        for h in range(H):\n",
    "            pixel_value = symbols(f'x_{c}_{w}_{h}')\n",
    "            image_array[c, w, h] = pixel_value\n",
    "\n",
    "# 生成した配列を表示\n",
    "print(\"Image Array:\")\n",
    "print(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f350a37",
   "metadata": {},
   "source": [
    "## P268をnumpyを使って再現する旅。PyTorchはテンソルの要素が数値のみを許可している。このため、P268をPyTorchではなく、numpyを使って再現する必要がある。\n",
    "#### ここでもPyTorch→numpyの翻訳にChatGPTは大活躍。。。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0762fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xを用意\n",
      "(2, 2, 2)\n",
      "[[[x_0_0_0,      x_0_0_1,     ]\n",
      "  [x_0_1_0,      x_0_1_1,     ]]\n",
      "\n",
      " [[x_1_0_0,      x_1_0_1,     ]\n",
      "  [x_1_1_0,      x_1_1_1,     ]]]\n",
      "Xにバッチ次元を追加する\n",
      "(1, 2, 2, 2)\n",
      "[[[[x_0_0_0,      x_0_0_1,     ]\n",
      "   [x_0_1_0,      x_0_1_1,     ]]\n",
      "\n",
      "  [[x_1_0_0,      x_1_0_1,     ]\n",
      "   [x_1_1_0,      x_1_1_1,     ]]]]\n",
      "XのサイズをB,C,W,H→B,C,Nに変形する\n",
      "(1, 2, 4)\n",
      "(1, 2, 4)\n",
      "[[[x_0_0_0,      x_0_0_1,      x_0_1_0,      x_0_1_1,     ]\n",
      "  [x_1_0_0,      x_1_0_1,      x_1_1_0,      x_1_1_1,     ]]]\n",
      "掛け算\n",
      "掛け算：前準備としてX_Tを作る\n",
      "(1, 4, 2)\n",
      "[[[x_0_0_0,      x_1_0_0,     ]\n",
      "  [x_0_0_1,      x_1_0_1,     ]\n",
      "  [x_0_1_0,      x_1_1_0,     ]\n",
      "  [x_0_1_1,      x_1_1_1,     ]]]\n",
      "掛け算：掛け算の本処理。bmmはmatmulと同じ\n",
      "(1, 4, 4)\n",
      "[[[x_0_0_0**2 + x_1_0_0**2,      x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1,      x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0,      x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1,     ]\n",
      "  [x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1,      x_0_0_1**2 + x_1_0_1**2,      x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0,      x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1,     ]\n",
      "  [x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0,      x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0,      x_0_1_0**2 + x_1_1_0**2,      x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1,     ]\n",
      "  [x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1,      x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1,      x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1,      x_0_1_1**2 + x_1_1_1**2,     ]]]\n",
      "↑について。行は各画素位置(この場合は(0,0),(0,1),(1,0),(1,1)の4パターン)毎に並ぶ。行の中身はその画素位置の各チャネルと、同じチャネルの違う画素位置との掛け算の和が並ぶ\n",
      "つまり、4*4で16個の要素があり、これが特徴量ということになる。\n",
      "次に、softmaxを求めるが、PyTorchと違い、numpyには組み込みのsoftmaxが無いため自作する必要がある。以下、Generated By Chat GPT\n",
      "規格化：実際に、softmaxを実行するとエラーになる。umr_maximumという関数でエラーになっているため、これは、おそらく要素が文字列なので、計算不可だからだろう\n",
      "という訳で、規格化は実際にせずに、規格化されたものとして理解をすすめる\n",
      "アテンションマップの表示（対称行列なので、転置してもそのままの様子）\n",
      "(1, 4, 4)\n",
      "[[[x_0_0_0**2 + x_1_0_0**2,      x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1,      x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0,      x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1,     ]\n",
      "  [x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1,      x_0_0_1**2 + x_1_0_1**2,      x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0,      x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1,     ]\n",
      "  [x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0,      x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0,      x_0_1_0**2 + x_1_1_0**2,      x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1,     ]\n",
      "  [x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1,      x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1,      x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1,      x_0_1_1**2 + x_1_1_1**2,     ]]]\n",
      "self-Attention Mapを計算する\n",
      "(1, 2, 4)\n",
      "[[[x_0_0_0*(x_0_0_0**2 + x_1_0_0**2) + x_0_0_1*(x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1) + x_0_1_0*(x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0) + x_0_1_1*(x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1),      x_0_0_0*(x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1) + x_0_0_1*(x_0_0_1**2 + x_1_0_1**2) + x_0_1_0*(x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0) + x_0_1_1*(x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1),      x_0_0_0*(x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0) + x_0_0_1*(x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0) + x_0_1_0*(x_0_1_0**2 + x_1_1_0**2) + x_0_1_1*(x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1),      x_0_0_0*(x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1) + x_0_0_1*(x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1) + x_0_1_0*(x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1) + x_0_1_1*(x_0_1_1**2 + x_1_1_1**2),     ]\n",
      "  [x_1_0_0*(x_0_0_0**2 + x_1_0_0**2) + x_1_0_1*(x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1) + x_1_1_0*(x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0) + x_1_1_1*(x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1),      x_1_0_0*(x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1) + x_1_0_1*(x_0_0_1**2 + x_1_0_1**2) + x_1_1_0*(x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0) + x_1_1_1*(x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1),      x_1_0_0*(x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0) + x_1_0_1*(x_0_0_1*x_0_1_0 + x_1_0_1*x_1_1_0) + x_1_1_0*(x_0_1_0**2 + x_1_1_0**2) + x_1_1_1*(x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1),      x_1_0_0*(x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1) + x_1_0_1*(x_0_0_1*x_0_1_1 + x_1_0_1*x_1_1_1) + x_1_1_0*(x_0_1_0*x_0_1_1 + x_1_1_0*x_1_1_1) + x_1_1_1*(x_0_1_1**2 + x_1_1_1**2),     ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Xを用意\")\n",
    "X = image_array\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(\"Xにバッチ次元を追加する\")\n",
    "X = np.expand_dims(X, axis=0)\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(\"XのサイズをB,C,W,H→B,C,Nに変形する\")\n",
    "print( (X.shape[0],X.shape[1], X.shape[2] * X.shape[3]))\n",
    "X = np.reshape(X, (X.shape[0],X.shape[1], X.shape[2] * X.shape[3]))\n",
    "print(X.shape)\n",
    "print(X)\n",
    "print(\"掛け算\")\n",
    "print(\"掛け算：前準備としてX_Tを作る\")\n",
    "X_T = np.transpose(X, (0,2,1))\n",
    "print(X_T.shape)\n",
    "print(X_T)\n",
    "print(\"掛け算：掛け算の本処理。bmmはmatmulと同じ\")\n",
    "S = np.matmul(X_T, X)\n",
    "print(S.shape)\n",
    "print(S)\n",
    "print(\"↑について。行は各画素位置(この場合は(0,0),(0,1),(1,0),(1,1)の4パターン)毎に並ぶ。行の中身はその画素位置の各チャネルと、同じチャネルの違う画素位置との掛け算の和が並ぶ\")\n",
    "print(\"つまり、4*4で16個の要素があり、これが特徴量ということになる。\")\n",
    "print(\"次に、softmaxを求めるが、PyTorchと違い、numpyには組み込みのsoftmaxが無いため自作する必要がある。以下、Generated By Chat GPT\")\n",
    "\n",
    "def softmax(x, axis=-1):\n",
    "    e_x = np.exp(x - x.max(axis=axis, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=axis, keepdims=True)\n",
    "\n",
    "print(\"規格化：実際に、softmaxを実行するとエラーになる。umr_maximumという関数でエラーになっているため、これは、おそらく要素が文字列なので、計算不可だからだろう\")\n",
    "print(\"という訳で、規格化は実際にせずに、規格化されたものとして理解をすすめる\")\n",
    "#m = softmax(S, axis=2)\n",
    "\n",
    "attention_map_T = S\n",
    "\n",
    "print(\"アテンションマップの表示（対称行列なので、転置してもそのままの様子）\")\n",
    "attention_map = np.transpose(attention_map_T, (0,2,1))\n",
    "print(attention_map.shape)\n",
    "print(attention_map)\n",
    "\n",
    "print(\"self-Attention Mapを計算する\")\n",
    "o = np.matmul(X, np.transpose(attention_map, (0,2,1)))\n",
    "print(o.shape)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b1a19",
   "metadata": {},
   "source": [
    "### ↑の結果は、第1次元がバッチ、第2次元がチャネル、第3次元が画素群である(X,Y要素がノベタで並んでいる）。第2次元を見ると、各チャネル毎に確かに、並んでいそうな事もわかる。そして、例えば具体的に[0][P][:]のPの並び(行の並び)を見ると、各チャネルの各画素について、大域的な数値が考慮されているようにも見える。\n",
    "\n",
    "### 最初の[0][0]を抜き出すと　x_0_0_0*(x_0_0_0**2 + x_1_0_0**2) + x_0_0_1*(x_0_0_0*x_0_0_1 + x_1_0_0*x_1_0_1) + x_0_1_0*(x_0_0_0*x_0_1_0 + x_1_0_0*x_1_1_0) + x_0_1_1*(x_0_0_0*x_0_1_1 + x_1_0_0*x_1_1_1),      である。これは、チャネル0の(0,0)に関するものである。なぜならというと、試しに、\"_0_0\"でこのノートを文字列検索すると、(0,0)に関するヒット数がこの行で一番多く、(0,0)に関して特徴量を計算しているものと考えられるためである。後の行も同様である。\n",
    "\n",
    "### この時点で抽象的な理解しかできない。この多項式を見て、ああ、そうだ、特徴を捉えるのに必要な計算式だ。とは到底、理解が追いつかない。実際の値の動きと合わせて見ていくしかないだろう。これを思いついた研究者は偉大としか思えない・・・"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
